\section{Chi tiết hoạt động của LOCUST}
\subsection{Định nghĩa người dùng và tác vụ}

Bắt đầu từ cốt lõi: mô tả ``người dùng ảo'' sẽ làm gì. Khi hành vi được khai báo rõ, mọi thứ tiếp theo (dữ liệu, kịch bản, tải) mới có nền tảng để triển khai.

\begin{itemize}
	\item \textbf{Lớp người dùng ảo (\texttt{HttpUser})}: Locust mô phỏng người dùng thông qua việc định nghĩa các lớp Python kế thừa \texttt{\textcolor{teal}{HttpUser}} (hoặc \textcolor{teal}{User} nếu không dùng HTTP). \textcolor{teal}{HttpUser} cung cấp client HTTP tích hợp sẵn để gửi requests đến hệ thống đích. Mỗi instance của \textcolor{teal}{HttpUser} đại diện cho một người dùng ảo độc lập với session riêng, thực hiện một tập hành vi cụ thể trên hệ thống.
	
	\item \textcolor{teal}{@task} \textbf{decorator – Định nghĩa tác vụ bằng \textcolor{teal}{@task}}: Bên trong lớp \textcolor{teal}{HttpUser}, các hành vi (scenario) của người dùng được định nghĩa dưới dạng các phương thức được đánh dấu bằng decorator \textcolor{teal}{@task}. Mỗi phương thức được trang trí bởi \textcolor{teal}{@task} được coi là một \textit{tác vụ} mà người dùng ảo sẽ thực hiện. Locust sẽ tạo nhiều instance của lớp người dùng và mỗi instance chọn ngẫu nhiên một tác vụ để chạy tại mỗi bước.
	
	\item \textbf{Trọng số task (task weight)}: Có thể gán trọng số cho tác vụ bằng cách truyền tham số vào \textcolor{teal}{@task}, ví dụ \textcolor{teal}{@task(3)}. Tác vụ có trọng số cao sẽ được chọn thực thi thường xuyên hơn (ví dụ trọng số 3 nghĩa là xác suất chạy tác vụ đó cao gấp \textasciitilde3 lần so với trọng số 1). Bên trong phương thức tác vụ, sử dụng \textcolor{teal}{self.client} (HTTP client tích hợp) để gửi các yêu cầu HTTP (GET, POST, ...); Locust sẽ tự động thu thập thời gian thực thi và kết quả (status code, độ trễ, ...) của các request này.
	
	\item \textcolor{teal}{wait\_time}: Định nghĩa thời gian chờ giữa các task để mô phỏng hành vi người dùng thực. Có thể sử dụng \textcolor{teal}{constant} (cố định), \textcolor{teal}{between} (ngẫu nhiên trong khoảng), hoặc \textcolor{teal}{constant\_pacing} (đảm bảo tần suất đều).
	
	\item \textbf{Hooks on\_start/on\_stop}: Có thể định nghĩa các phương thức đặc biệt \textcolor{teal}{on\_start(self)} và \textcolor{teal}{on\_stop(self)} trong lớp người dùng. \textcolor{teal}{on\_start} sẽ được Locust gọi \textbf{một lần} khi mỗi user ảo bắt đầu phiên chạy của nó -- thường dùng để thực hiện bước khởi tạo, ví dụ đăng nhập hoặc thiết lập dữ liệu ban đầu. Tương tự, \textcolor{teal}{on\_stop} được gọi khi người dùng ảo kết thúc (khi test dừng hoặc người dùng bị loại bỏ), thường dùng để dọn dẹp, ví dụ đăng xuất hoặc giải phóng tài nguyên. Các hook này giúp mô phỏng chính xác hơn vòng đời của một phiên người dùng.
	
	\item \textbf{Stateful flow}: Cho phép duy trì trạng thái qua các request như session cookies, authentication tokens, hoặc dữ liệu context. Điều này quan trọng để mô phỏng luồng giao dịch liên tiếp của người dùng thực.
\end{itemize}

\vspace{0.5em}
\noindent\textbf{Đoạn code Python dưới đây định nghĩa một lớp người dùng ảo với hai tác vụ đơn giản, sử dụng trọng số, thời gian chờ và hook \texttt{on\_start}/\texttt{on\_stop}:}
\vspace{0.5em}

\begin{lstlisting}
	from locust import HttpUser, task, between
	
	class WebsiteUser(HttpUser):
	wait_time = between(1, 5)
	
	def on_start(self):
	self.client.post("/login", json={"username": "test", "password": "test"})
	
	def on_stop(self):
	self.client.post("/logout")
	
	@task(3)
	def view_home(self):
	self.client.get("/")
	
	@task(1)
	def view_profile(self):
	self.client.get("/profile")
\end{lstlisting}

\newpage
\subsection{Chuẩn bị và tạo dữ liệu}

Sau khi biết user ảo sẽ làm gì, ta cần chuẩn bị “dao cụ”. Giai đoạn này nhằm tạo ra dữ liệu, tài khoản và môi trường để các hành vi được thực thi ổn định và tái lặp.

\begin{itemize}
	\item \textbf{Chuẩn bị dữ liệu mẫu trước khi test:} Trước khi chạy tải bằng Locust, cần đảm bảo hệ thống có sẵn dữ liệu phù hợp. Nên có bộ dữ liệu thử riêng (fixtures) để phục vụ kiểm thử hiệu năng, ví dụ: tập tài khoản người dùng thử, danh sách sản phẩm mẫu, hoặc bản định sẵn cơ sở dữ liệu nhỏ phục vụ các thao tác cố định.
\end{itemize}

\vspace{1em}
\paragraph{Tạo 100 user thử (với curl + shell):}
\vspace{0.5em}
\noindent

\begin{lstlisting}[language=bash]
	for i in $(seq 1 100); do
	curl -X POST https://api.example.com/admin/seed-user \
	-H "Authorization: Bearer <ADMIN_TOKEN>" \
	-H "Content-Type: application/json" \
	-d '{"username":"test'$i'","password":"Pass@123","role":"customer"}'
	done
\end{lstlisting}

\vspace{0.5em}
\paragraph{Seed 1.000 sản phẩm mẫu:}
\vspace{0.5em}
\noindent

\begin{lstlisting}[language=bash]
	curl -X POST https://api.example.com/admin/seed-products \
	-H "Authorization: Bearer <ADMIN_TOKEN>" \
	-H "Content-Type: application/json" \
	--data-binary @products_seed.json
\end{lstlisting}

\vspace{1em}
\begin{itemize}
	\item \textbf{Sử dụng fixture và khởi tạo dữ liệu trong code:} Có thể nhúng dữ liệu mẫu ngay trong script Locust hoặc đọc từ file bên ngoài. Ví dụ: lưu danh sách tài khoản thử trong file CSV rồi đọc vào một biến toàn cục. Mỗi người dùng ảo khi \texttt{on\_start} có thể lấy ngẫu nhiên một cặp username/password từ danh sách này để đăng nhập. Đảm bảo mỗi user ảo độc lập về dữ liệu (ví dụ mỗi user dùng một bộ định danh riêng) để kết quả test không bị sai lệch do các user tác động lẫn nhau.
	\item \textbf{Dữ liệu đăng nhập và người dùng thử:} Nếu kịch bản hiệu năng bao gồm bước đăng nhập, hãy tạo sẵn danh sách thông tin đăng nhập cho nhiều người dùng thử. Mỗi user ảo trong Locust nên sử dụng một tài khoản riêng (hoặc một tập hợp các tài khoản – \textit{pool credentials})  để mô phỏng chân thực việc nhiều người dùng đồng thời đăng nhập. Tránh việc tất cả user ảo dùng chung một thông tin đăng nhập, vì có thể dẫn đến tranh chấp (ví dụ: ghi đè \textit{session} của nhau) hoặc không đúng hành vi thực tế. Ví dụ dưới đây minh họa việc: Đọc CSV và cấp phát tuần tự (round-robin) cho mỗi VU:
	
\end{itemize}

\vspace{0.5em}
\paragraph{Đọc CSV và khởi tạo từ tệp:}
\vspace{0.5em}
\noindent

\begin{lstlisting}[language=Python, breaklines=true, breakatwhitespace=true]

	import csv, itertools
	from locust import HttpUser, task
	
	with open("users.csv", newline="") as f:
	USERS = list(csv.DictReader(f))  # cot: username,password
	_pool = itertools.cycle(USERS)   
	
	class LoginUser(HttpUser):
	def on_start(self):
	creds = next(_pool)
	self.username = creds["username"]
	self.client.post("/login", json=creds)
	
	def on_stop(self):
	self.client.post("/logout", json={"username": self.username})
	
	@task
	def home(self):
	self.client.get("/")
\end{lstlisting}

\vspace{0.5em}
\begin{itemize}
	\item\textbf{Seed dữ liệu và teardown:} Trong trường hợp kịch bản cần một lượng lớn dữ liệu (ví dụ hàng vạn bản ghi đơn hàng để truy vấn), nên thực hiện bước \textit{seed} (tạo dữ liệu sẵn) trước khi chạy Locust, thay vì để user ảo tự tạo trong lúc chạy (điều này có thể làm nhiễu kết quả và tốn thời gian test). Sau khi kết thúc test, thực hiện \textit{teardown} – tức là xóa hoặc dọn dẹp các dữ liệu thử đã sinh ra (ví dụ: xóa những đơn hàng test, người dùng test khỏi database) để môi trường trở lại trạng thái sạch cho lần chạy sau. Việc này giúp tránh \textit{ô nhiễm môi trường test} (pollution) và đảm bảo mỗi lần test đều bắt đầu trên nền dữ liệu như nhau.
\end{itemize}

\vspace{1em}
\noindent
Sau khi Locust kết thúc (CI/CD pipeline step)
teardown DB bằng script sau khi kết thúc (runner ngoài Locust)

\vspace{0.5em}
\begin{lstlisting}[language=Python, breaklines=true, breakatwhitespace=true]
	python teardown_db.py --tag "loadtest-2025-10-18"
\end{lstlisting}

\newpage
\subsection{Luồng trạng thái và kịch bản}
\vspace{0.5em}

Khi dữ liệu đã sẵn, Locust cho phép ta thiết kế “đường đi” của người dùng theo luồng tuần tự, rẽ nhánh, và tỷ lệ pha trộn để phản ánh lưu lượng thực tế.

\begin{itemize}
	\item \textbf{Kịch bản tuần tự/thành phần}: Locust cho phép mô phỏng các chuỗi hành động người dùng theo trình tự xác định. Mặc định, mỗi user sẽ bỏ chọn ngẫu nhiên các tác vụ đã định nghĩa, nhưng nếu muốn mô phỏng một luồng có định (ví dụ: \textit{mở trang chủ → tìm sản phẩm → thêm vào giỏ → thanh toán}), ta có thể gọi các bước này vào trong một tác vụ duy nhất (một phương thức \textbf{\textcolor{teal}{@task}} thực hiện tuần tự nhiều request) để đảm bảo trình tự. Locust cũng hỗ trợ lớp \textbf{\textcolor{teal}{SequentialTaskSet}} cho phép khai báo nhiều phương thức tác vụ và đảm bảo chúng chạy tuần tự theo thứ tự định nghĩa, thay vì ngẫu nhiên.
	
	\item \textbf{Duy trì trạng thái giữa các bước}: Khi kịch bản có nhiều bước liên quan, ta có thể lưu trạng thái trong biến của user để dùng cho các bước sau. Ví dụ: sau khi login ở bước đầu (\textbf{\textcolor{teal}{on\_start}}), lưu lại token phiên (\textbf{\textcolor{teal}{self.token}}). Hoặc nếu bước 1 lấy về một \textbf{\textcolor{teal}{order\_id}}, ta gán \textbf{\textcolor{teal}{self.order\_id = ...}} để bước 2 có thể sử dụng \textbf{\textcolor{teal}{self.order\_id}} trong request tiếp theo. Việc duy trì trạng thái trong đối tượng user (hoặc TaskSet) giúp mô phỏng đúng chuỗi giao dịch liên tục của một người dùng thật.
	
	\item \textbf{Phân nhánh luồng (branching)}: Không phải tất cả người dùng đều theo cùng một lộ trình; Locust cho phép mô phỏng các hành vi rẽ nhánh bằng cách sử dụng logic điều kiện hoặc xác suất trong code. Ví dụ: một tác vụ có thể viết
	\begin{lstlisting}[language=Python]
		if random.random() < 0.2:
		# thực hiện nhánh A
		else:
		# thực hiện nhánh B
	\end{lstlisting}
	để 20\% người dùng đi theo nhánh A (ví dụ: mua hàng) trong khi 80\% đi theo nhánh B (ví dụ: chỉ xem sản phẩm). Cách khác, có thể định nghĩa nhiều tác vụ tương ứng với các nhánh khác nhau và gán trọng số để phản ánh tỷ lệ xảy ra của mỗi nhánh trong tập người dùng.
	
	\item \textbf{Think-time trong kịch bản}: Ngoài việc dùng \textbf{\textcolor{teal}{wait\_time}} để nghỉ giữa các tác vụ, ta có thể thêm thời gian chờ bên trong một kịch bản tuần tự để mô phỏng việc người dùng \textit{lướt lại suy nghĩ hoặc đọc nội dung}. Ví dụ: sau khi tải trang sản phẩm, có thể dùng \textbf{\textcolor{teal}{time.sleep(2)}} (hoặc \textbf{\textcolor{teal}{gevent.sleep(2)}}) để giả lập người dùng xem thông tin trong 2 giây trước khi thêm sản phẩm vào giỏ. Việc đưa think-time vào luồng giúp hành vi người dùng đo sát thực tế hơn và tránh tạo tải không tự nhiên (người dùng thật thường không spam request liên tục).
	
	\item \textbf{Kết hợp nhiều luồng người dùng}: Để mô phỏng \textit{mix traffic} -- trộn kết hợp nhiều loại người dùng với hành vi khác nhau trong cùng một test. Có thể sử dụng nhiều lớp \textbf{\textcolor{teal}{HttpUser}} khác nhau cho mỗi loại kịch bản. Mỗi lớp người dùng có thể đại diện cho một vai trò hoặc trường hợp sử dụng (ví dụ: người dùng khách, người dùng đăng nhập mua hàng). Sử dụng thuộc tính \textbf{\textcolor{teal}{weight}} ở cấp lớp người dùng để điều chỉnh tỷ lệ giữa các kịch bản này khi chạy đồng thời (ví dụ: \textbf{\textcolor{teal}{class Buyer(HttpUser): weight = 3}} và \textbf{\textcolor{teal}{class Guest(HttpUser): weight = 1}} để có 75\% người dùng là người mua, 25\% là khách vãng lai). Locust sẽ phân bổ số lượng user ảo theo trọng số đã chỉ định.
	
	\item \textbf{Sử dụng tag cho kịch bản}: Locust cho phép gắn nhãn cho tác vụ hoặc TaskSet bằng decorator \textbf{\textcolor{teal}{@tag("tên\_nhãn")}}.
	\begin{itemize}
		\item Tính năng này hữu ích khi muốn chạy một phần cụ thể của kịch bản. Ví dụ: có thể đánh dấu các tác vụ liên quan đến luồng “thanh toán” bằng tag \textbf{\textcolor{teal}{"checkout"}}. Khi chạy test, ta có thể dùng tham số dòng lệnh \textbf{\textcolor{teal}{--tags checkout}} để chỉ chạy những tác vụ có nhãn đó (hoặc \textbf{\textcolor{teal}{--exclude-tags}} để loại trừ). Điều này giúp linh hoạt trong việc thử nghiệm từng phần của kịch bản hoặc tập trung vào điểm nóng cụ thể mà không cần tách hẳn thành file Locust khác.
		
		\item Ngoài ra, gắn tags cho các tasks hoặc requests để phân loại và lọc kết quả. Ví dụ: tag \textbf{\textcolor{teal}{"read"}} cho GET requests, \textbf{\textcolor{teal}{"write"}} cho POST/PUT, giúp phân tích riêng performance của từng nhóm operations.
	\end{itemize}
	
\end{itemize}

\vspace{0.5em}
\begin{lstlisting}[language=Python, breaklines=true, breakatwhitespace=true, 
	caption={Mô phỏng hành vi người dùng với tuần tự, nhánh, think-time, tag và mix traffic},
	label={lst:browseflow-mixed-traffic}]
	import random
	import gevent
	from locust import HttpUser, SequentialTaskSet, task, tag, between
	
	# ----------------------------
	# 1) TaskSet tuan tu, giu trang thai, re nhanh & think-time
	# ----------------------------
	class BrowseFlow(SequentialTaskSet):
	def on_start(self):
	# (Tuy chon) giu trang thai phien: token, cart_id...
	# Vi duj gia dinh login ben ngoai hoac khong can login
	self.selected_product_id = None
	
	@task
	@tag("read", "list")
	def list_products(self):
	# Buoc 1 : Xem danh sach san pham
	res = self.user.client.get("/products")
	if res.ok:
	items = res.json().get("items", [])
	if items:
	# Giu trang thai de dung cho buoc sau
	self.selected_product_id = items[0]["id"]
	# Think-time tu nhien : nguoi dung dung doc 1.5s
	gevent.sleep(1.5)
	
	@task
	@tag("read", "detail")
	def view_detail(self):
	# Buoc 2 : Xem chi tiet san pham da chon o Buoc truoc
	if self.selected_product_id:
	self.user.client.get(f"/products/{self.selected_product_id}")
	gevent.sleep(0.8)
	
	@task
	@tag("write", "checkout")
	def maybe_checkout(self):
	# Buoc 3 : Re nhanh co xac suat (20%) thuc hien mua hang
	if self.selected_product_id and random.random() < 0.2:
	self.user.client.post("/cart", json={"id": self.selected_product_id})
	self.user.client.post("/checkout")
	# Ket thuc 1 vong flow, quay lai buoc dau (SequentialTaskSet lap lai)
	gevent.sleep(0.5)
	
	# ----------------------------
	# 2) Nhieu lop HttpUser de mo phong mix traffic
	# ----------------------------
	class Guest(HttpUser):
	"""
	Khach vang lai: Chi duyet trang chu hoac danh sach
	weight = 1  -> Chiem ti le nho hon (Vi du 25% neu Buyer = 3)
	"""
	wait_time = between(1, 3)
	weight = 1
	
	@task(3)
	@tag("read", "home")
	def home(self):
	self.client.get("/")
	
	@task(1)
	@tag("read", "list")
	def list(self):
	self.client.get("/products")
	
	class Buyer(HttpUser):
	"""
	Nguoi mua : chay flow tuan tu BrowseFlow.
	weight = 3 -> chiem ti le cao hon( vi du 75% )
	"""
	wait_time = between(1, 2)
	tasks = [BrowseFlow]
	weight = 3
\end{lstlisting}

\subsection{Cấu hình tải và thực thi}
\begin{itemize}
	\item \textbf{Số lượng user ảo và tốc độ sinh user:} Cấu hình tải trong Locust chủ yếu dựa vào hai tham số chính: \textit{\uline{số lượng người dùng đồng thời và tốc độ tạo người dùng mới}}.
	 Số lượng user (thường ký hiệu -u hoặc --users) xác định có tối đa bao nhiêu người dùng ảo hoạt động cùng lúc trong test. Tốc độ spawn rate (ký hiệu -r hoặc --spawn-rate) xác định số user ảo khởi tạo mỗi giây cho đến khi đạt tổng số yêu cầu. Ví dụ: \textcolor{teal}{-u 1000 -r 50} nghĩa là tăng dần đến 1000 user ảo với tốc độ 50 user mỗi giây. Việc điều chỉnh spawn rate giúp mô phỏng kịch bản ramp-up dần dần thay vì đột ngột tạo toàn bộ user (tránh gây sốc tải tức thời trừ khi đó là tình huống cần test).
	
\end{itemize}

\vspace{0.5em}
\begin{lstlisting}[caption={Kịch bản ba giai đoạn tải: ramp-up → giữ ổn định → ramp-down}, label={lst:stage-shape}]
	# locustfile.py
	from locust import HttpUser, task, between, LoadTestShape
	
	class ShopUser(HttpUser):
	wait_time = between(1, 3)
	
	@task
	def browse(self):
	self.client.get("/products")
	
	# Stages/steps: ramp-up → hold → ramp-down
	class StagesShape(LoadTestShape):
	stages = [
	{"duration": 60, "users": 100, "spawn_rate": 20},  # 1) ramp-up 100 user trong 60s
	{"duration": 360, "users": 100, "spawn_rate": 20}, # 2) giu on dinh 5 phut (tong 6 phut)
	{"duration": 420, "users": 0,   "spawn_rate": 50}, # 3) ramp-down trong 1 phut
	]
	
	def tick(self):
	run_time = self.get_run_time()
	for s in self.stages:
	if run_time < s["duration"]:
	return (s["users"], s["spawn_rate"])
	return None  # End test
\end{lstlisting}

\begin{itemize}
	\item \textbf{Thời gian chạy test:} Locust cho phép đặt thời gian giới hạn cho bài test. Mặc định, nếu không chỉ định, test sẽ chạy cho đến khi người vận hành dừng thủ công. Để tự động dừng sau một khoảng thời gian, có thể dùng tuỳ chọn \textcolor{teal}{-t} hoặc \textcolor{teal}{--run-time}, ví dụ: \textcolor{teal}{-t 5m} để chạy trong 5 phút rồi kết thúc. Cần chọn thời gian đủ dài để thu thập số liệu ổn định (thường vài phút trở lên), nhưng cũng không nên quá dài trừ khi cần kiểm tra độ bền (soak test).
	
	\item \textbf{Stages/steps:} Định nghĩa các giai đoạn tải khác nhau trong test. Ví dụ: ramp-up 100 users trong 1 phút, giữ ổn định 5 phút, ramp-down về 0. Locust cung cấp \texttt{LoadTestShape} class cho phép tạo load patterns phức tạp.
	
	\item \textbf{Thực thi qua giao diện Web UI:} Khi chạy Locust mà \textbf{không} dùng chế độ headless, Locust sẽ khởi động một web UI (mặc định tại \textbf{\uline{http://localhost:8089}}). Qua giao diện này, người dùng có thể nhập số users, spawn rate, thời gian chạy và nhấn \texttt{Start} để bắt đầu test. Web UI cung cấp bảng số liệu và biểu đồ thời gian thực về thông lượng, độ trễ, tỉ lệ lỗi... giúp quan sát trực quan trong khi test đang chạy. Đây là cách thuận tiện để thực hiện thử nghiệm thủ công hoặc phân tích tương tác thời gian thực.
	
	\item \textbf{Thực thi bằng dòng lệnh (CLI) / chế độ headless:} Đối với chạy tự động (ví dụ trong pipeline CI/CD) hoặc khi không cần giao diện đồ hoạ, Locust hỗ trợ chế độ headless. Sử dụng cờ \textcolor{teal}{--headless} kèm các tham số cần thiết (\texttt{-u}, \textcolor{teal}{-r}, \textcolor{teal}{-t}, \textcolor{teal}{-H} cho host, v.v.) để Locust chạy ngay bài test từ dòng lệnh. Ở chế độ này, kết quả sẽ được log ra console theo chu kỳ (mặc định mỗi 5s in thống kê một lần). Chế độ headless cho phép tích hợp dễ dàng với script và thu thập kết quả bằng file hoặc log mà không cần sự can thiệp của con người. Lưu ý khi chạy headless, nên chỉ định rõ ràng các tham số, và có thể dùng thêm \textcolor{teal}{--csv} để xuất kết quả ra file.
\end{itemize}

\vspace{0.5em}
\noindent

\begin{lstlisting}[language=bash, caption={Ví dụ chạy Locust ở chế độ headless và xuất file CSV}, label={lst:locust-cli-example}]
	# 1000 users, spawn 50/s, run 10 phút, ghi CSV
	locust -f locustfile.py --headless -H https://api.example.com \
	-u 1000 -r 50 -t 10m --csv run_2025_10_22
\end{lstlisting}

\vspace{0.5em}
\begin{itemize} 
	\item \textbf{Chế độ phân tán (master--worker):} Locust được thiết kế để có thể sinh tải phân tán trên nhiều máy. Điều này hữu ích khi một máy đơn lẻ không đủ tài nguyên tạo lượng user mong muốn. Cấu hình master–worker: khởi chạy một tiến trình Locust làm \textbf{Master} (ví dụ: \textcolor{teal}{locust -f test.py --master}), sau đó khởi chạy một hoặc nhiều tiến trình Locust khác làm \textbf{Worker} với cờ \textcolor{teal}{--worker --master-host=<địa\_chỉ\_master>}. Master sẽ đóng vai trò điều phối: nó nhận cấu hình test (số user, spawn rate) và phân phối người dùng cho các worker, đồng thời thu thập số liệu từ chúng để tổng hợp báo cáo thống nhất. Các worker chỉ lo việc mô phỏng user và gửi kết quả về master. Giao tiếp qua ZeroMQ. Mô hình này cho phép dễ dàng mở rộng quy mô test bằng cách tăng số lượng worker, vượt quá giới hạn tài nguyên của một máy đơn lẻ.
\end{itemize}

\vspace{0.5em}
\texttt{\# Master (điều phối + UI)} \\
\texttt{locust -f locustfile.py --master --web-port 8089}

\vspace{0.5em}
\texttt{\# Worker (1 hoặc nhiều máy)} \\
\texttt{locust -f locustfile.py --worker --master-host 10.0.0.1}

\vspace{0.5em}
\begin{itemize}
	\item \textbf{Triển khai bằng Docker/Kubernetes:} Để thuận tiện và linh hoạt, có thể chạy Locust trong Docker containers. Locust cung cấp image Docker chính thức; người dùng có thể dùng một container làm \textbf{master} và nhiều container khác làm \textbf{worker}. Ví dụ:
	
	\begin{lstlisting}[language=bash, caption={Chạy master và worker với Docker}, label={lst:docker-locust}]
		docker run -p 8089:8089 locustio/locust:latest -f /mnt/locustfile.py --master
		docker run locustio/locust:latest -f /mnt/locustfile.py --worker \
		--master-host="master_container_ip"
	\end{lstlisting}
	
	Tương tự, trên Kubernetes có thể triển khai Locust master và worker dưới dạng Deployment/Pod, triển khai thông qua Helm chart có sẵn. Việc container hóa giúp dễ dàng tích hợp hệ thống và hạ tầng hiện có, chỉnh cấu hình, cũng như tăng/giảm số lượng worker nhanh chóng phù hợp với kịch bản tải.
	
	\textbf{Ví dụ docker-compose.yml:}
	
	\begin{lstlisting}[language=yaml, caption={Cấu hình docker-compose Locust}, label={lst:docker-compose}]
		services:
		master:
		image: locustio/locust
		command: -f /mnt/locustfile.py --master --web-port 8089
		ports: ["8089:8089"]
		volumes: ["/locustfile.py:/mnt/locustfile.py"]
		
		worker:
		image: locustio/locust
		command: -f /mnt/locustfile.py --worker --master-host master
		depends_on: [master]
		volumes: ["/locustfile.py:/mnt/locustfile.py"]
		deploy:
		replicas: 4  # scale nhanh s ố worker
	\end{lstlisting}
	
	\textbf{Tóm tắt các tham số:}
	\begin{itemize}
		\item \textbf{Users/Spawn-rate:} kiểm soát mức đồng thời và tốc độ nở tải.
		\item \textbf{Run-time:} dùng từ dòng lệnh hoặc dựa vào \texttt{LoadTestShape}.
		\item \textbf{Stages/steps:} mô tả ramp-up/hold/ramp-down bằng \texttt{LoadTestShape}.
		\item \textbf{Web UI:} thao tác thủ công, quan sát realtime.
		\item \textbf{CLI/headless:} chạy tự động, xuất CSV.
	\end{itemize}
\end{itemize}

\subsection{Thu thập số liệu \& tiêu chí vượt/không vượt}

\begin{itemize}
	\item \textbf{Các số liệu hiệu năng chính:} Locust sẽ tự động thu thập và hiển thị nhiều metric quan trọng trong quá trình test. Bao gồm:
	\begin{itemize}
		\item \textbf{Requests per second (RPS):} số lượng request gửi đi mỗi giây (càng nhiều là thông lượng hệ thống xử lý tốt).
		\item \textbf{Tỷ lệ lỗi (error rate):} phần trăm số request thất bại (mã HTTP >= 400).
		\item \textbf{Thời gian phản hồi trung bình (average response time)} và các phân vị thời gian phản hồi như \textbf{P50 (median)}, \textbf{P90}, \textbf{P95}, \textbf{P99} – cho biết phân bố độ trễ (ví dụ P95 = 500ms nghĩa là 95\% số request có thời gian $\leq$ 500ms).
		\item Ngoài ra còn có số lượng kết nối người dùng đang hoạt động, tổng số request đã thực hiện, v.v.
	\end{itemize}
	Các metric này đặc biệt quan trọng để đánh giá trải nghiệm người dùng và hiệu năng hệ thống.
	
	\item \textbf{Xác định tiêu chí Pass/Fail:} Trước khi test, cần đặt ra tiêu chuẩn chấp nhận hiệu năng (SLA hoặc SLO). 
	Ví dụ: \textit{99\% request phải dưới 1 giây, throughput tối thiểu 200 req/s, và tỷ lệ lỗi không quá 0.5\%}. 
	Sau khi chạy, dựa trên số liệu thu thập, đánh giá xem hệ thống vượt hay không vượt tiêu chí. Nếu bất kỳ chỉ số nào vượt quá ngưỡng cho phép (ví dụ thời gian P99 cao hơn 1 giây, hoặc error rate vượt 0.5\%) thì bài test bị coi là thất bại (fail về hiệu năng). 
	Ngược lại, nếu tất cả tiêu chí đều thỏa, hệ thống được xem là đạt yêu cầu dưới tải kiểm thử.
	
	\item \textbf{Thiết lập ngưỡng và giám sát khi chạy:} 
	Locust cho phép người viết kịch bản thiết lập các sự kiện xử lý động dựa trên số liệu thống kê. 
	Ví dụ: có thể sử dụng hook \textcolor{teal}{events.request\_failure} để đếm số lỗi và nếu tỷ lệ lỗi vượt quá 5\% thì tự động dừng test sớm. 
	Hoặc dùng hook \textcolor{teal}{events.quitting} để kiểm tra các thống kê tổng thể khi kết thúc: nếu \textcolor{teal}{environment.stats.total\_fail\_ratio} (tỷ lệ thất bại) vượt quá một ngưỡng nào đó,\\
	ta có thể đặt \textcolor{teal}{environment.process\_exit\_code = 1} để báo hiệu test không đạt (trả mã exit code khác 0 cho CI/CD). 
	Những cơ chế này giúp tự động hóa đánh giá pass/fail thay vì kiểm tra thủ công.
	
	\item \textbf{Báo cáo và xuất khẩu số liệu:} 
	Sau khi hoàn thành test, việc lưu trữ và phân tích số liệu rất quan trọng. Locust hỗ trợ xuất báo cáo ra file CSV bằng tham số \textcolor{teal}{--csv <tên\_file\_prefix>}, kết quả sẽ gồm các file CSV chứa thống kê (theo từng khoảng thời gian và tổng kết). 
	Các file này có thể được mở bằng công cụ phân tích (Excel, Python, v.v.) để vẽ biểu đồ chi tiết hoặc so sánh giữa các lần chạy khác nhau.
	
	Ngoài ra, Locust có thể tích hợp với hệ thống giám sát như Prometheus: thông qua \texttt{Prometheus exporter}, các metric của Locust có thể được đẩy hoặc scrape định kỳ và hiển thị trên Grafana theo thời gian thực.
	
	Cách làm phổ biến là chạy một exporter (ví dụ dự án \textcolor{teal}{locust\_exporter}) lắng nghe số liệu từ Locust và cung cấp endpoint \textcolor{teal}{/metrics} cho Prometheus. 
	Nhờ đó, nhóm kiểm thử có thể quan sát hiệu năng tổng thể dưới kịch bản hoạt động nặng, so sánh với baseline tài nguyên hệ thống cùng thời điểm và theo dõi xu hướng.
\end{itemize}

\subsection{Hỗ trợ giao thức \& mở rộng}

\begin{itemize}
	\item \textbf{Hỗ trợ mặc định HTTP/HTTPS:} Locust đã hỗ trợ tích hợp sẵn cho giao thức HTTP/HTTPS thông qua lớp \textcolor{teal}{HttpUser} và thư viện requests (đã được patch với gevent để hoạt động bất đồng bộ). Điều này phù hợp cho việc load test các web application, REST API. Tuy nhiên, Locust không gọi chỉ đến test các HTTP -- nó có thể được mở rộng để kiểm thử hầu hết các hệ thống/giao thức khác thông qua code Python.
	
	\item \textbf{Kiểm thử các giao thức khác (gRPC, WebSocket, MQ...):} Để sử dụng Locust với các giao thức phi HTTP, ta thường phải tự viết client hoặc dùng thư viện phụ hợp và tích hợp thủ công với Locust. Nguyên tắc chung là: thực hiện thao tác giao tiếp bằng thư viện Python tương ứng (ví dụ dùng \textcolor{teal}{grpclio} để gõ gRPC, dùng thư viện websocket-client cho WebSocket, hoặc driver cho MQ như Pika cho RabbitMQ), sau đó gọi các sự kiện của Locust để ghi nhận kết quả. Từ đó, Locust cung cấp event \textcolor{teal}{Environment.events.request} để tự log request tùy chỉnh. Lập trình viên có thể fire event này với các data như tên request, thời gian, kích thước, kết quả (hoặc exception nếu lỗi) khi mô hình thành một giao thức custom, các số liệu sẽ ghi nhận như các request thông thường. Lưu ý: để đạt hiệu quả cao, các thư viện client sử dụng nên \textbf{tương thích với \textcolor{teal}{gevent}} (non-blocking), nếu không sẽ làm giới hạn số lượng user đồng thời trên mỗi worker.
	
	\item \textbf{Sử dụng extension có sẵn:} Cộng đồng Locust có nhiều \textbf{phần mở rộng} hỗ trợ giao thức khác giúp giảm công sức viết tay. Ví dụ: gói \textcolor{teal}{locust-plugins} cung cấp sẵn lớp \textcolor{teal}{GrpcUser} để test gRPC hoặc \textcolor{teal}{WebSocketUser} để test thông qua WebSocket (sử dụng thư viện như websockets hoặc socket.io). Tài liệu Locust cũng có mẫu code cho việc test MQTT, XML-RPC, v.v. thông qua việc wrap client và fire event. Khi cần kiểm thử giao thức đặc thù, nên tìm kiếm xem đã có plugin hoặc hướng dẫn có sẵn, từ đó tuỳ biến theo nhu cầu. Nếu không khả năng mở rộng linh hoạt, Locust có thể dùng cho nhiều loại hệ thống: từ web, mobile API đến ví dụ như message queue, v.v.
	
	\item \textbf{Hooks và event tùy chỉnh:} Locust cung cấp cơ chế hook/event mạnh mẽ cho phép mở rộng chức năng mà không cần sửa mã nguồn Locust. Ngoài các hook cho request như đã đề cập, còn có các sự kiện khác như:
	\begin{itemize}
		\item \textcolor{teal}{test\_start}, \textcolor{teal}{test\_stop} (kích hoạt khi bắt đầu/kết thúc toàn bộ test),
		\item \textcolor{teal}{spawn\_complete} (khi đã sinh xong toàn bộ user),
		\item \textcolor{teal}{user\_error} (khi có exception không được xử lý trong task của user), v.v.
		
		Người dùng có thể đăng ký callback vào những event này để thực hiện các hành động tùy chỉnh. Ví dụ: dùng \textcolor{teal}{events.test\_start.add\_listener} để thiết lập cấu hình logging đặc biệt hoặc đánh dấu thời gian bắt đầu; dùng \textcolor{teal}{events.test\_stop.add\_listener} để thu thập và lưu trữ thêm số liệu (như kết nối trung bình mở trong DB, v.v.) hoặc gửi thông báo khi test kết thúc. Với \textcolor{teal}{events.request\_success} và \textcolor{teal}{events.request\_failure}, có thể ghi log chi tiết từng request ra file ngoài, hoặc tích hợp gửi metric tới hệ thống giám sát bên ngoài (như gửi dữ liệu lên StatsD/Graphite). Cơ chế hooks và events giúp mở \textbf{rộng Locust} vượt khỏi tính năng mặc định, mở ra các nhu cầu đo đạc và ghi nhận chuyển biến trong những tình huống phức tạp.
	\end{itemize}
	
	\item \textbf{Tuỳ chỉnh client và logic nâng cao:} Ngoài ra, do kịch bản Locust thực chất là code Python, người dùng có thể tuỳ ý tích hợp kịch bản logic nâng cao hơn. Ví dụ: tự đo thời gian cho một nhóm thao tác phức tạp (sử dụng \textcolor{teal}{@tag}, \textcolor{teal}{time.time()}) trước và sau để tính toán), ghi theo dạng JSON để dễ phân tích, hoặc thậm chí điều chỉnh hành vi user theo phân hồi nhận được (ví dụ: nếu nhận mã HTTP 500 thì chuyển sang nhóm hành động khác). Nhờ điều này mà khi thực hiện trong code Locust, làm test có thể gạt rất linh hoạt trong việc mô phỏng và đo đạc các tình huống tùy ý.
\end{itemize}


\subsection{Các lỗi/vấn đề thường phát hiện}

\begin{itemize}
	\item \textbf{Timeout (quá thời gian phản hồi):} Dưới tải nặng, một lỗi phổ biến là nhiều request bị \textit{timeout} – nghĩa là hệ thống không phản hồi trong thời gian chờ tối đa. Điều này cho thấy hệ thống không xử lý kịp lưu lượng hoặc có thể có điểm nghẽn nghiêm trọng. Locust sẽ ghi nhận các timeout như là lỗi (thất bại) và thông qua đó nhóm phát triển có thể xác định ngưỡng tải tại đó hệ thống bắt đầu mất phản hồi. Timeout thường đi kèm việc cần tối ưu hiệu năng hoặc tăng tài nguyên cho hệ thống.
	
	\item \textbf{Hiện tượng spike đột biến:} Khi chạy thử tải, có thể quan sát những lúc đột ngột tỷ lệ lỗi tăng đột ngột, không tuyến tính so với mức tải – gọi là \textit{spike}. Ví dụ, khi tăng user từ 100 lên 200 có thể thời gian phản hồi vượt tăng gấp nhiều lần, rồi sau đó giảm hoặc ổn định lại. Spike cũng có thể xảy ra do hành vi của hệ thống: như chu kỳ \textit{garbage collection}, reset kết nối, hay tải lại cache. Những biến động đột ngột này là dấu hiệu để điều tra nguyên nhân tiềm ẩn (bottleneck ẩn, cấu hình chưa phù hợp) trong hệ thống.
	
	\item \textbf{Lỗi 429 Too Many Requests:} Mã trạng thái HTTP 429 xuất hiện khi hệ thống hoặc dịch vụ trung gian (load balancer, API gateway) áp dụng giới hạn tần suất và bắt đầu từ chối các yêu cầu vì vượt quá hạn mức. Nếu trong bài test Locust xuất hiện nhiều 429, điều đó cho thấy ta đã đặt (hoặc vượt) ngưỡng giới hạn mà hệ thống cho phép. Đây có thể là hành vi mong đợi (nếu có cơ chế \textit{rate limit}) nhưng cũng có thể báo hiệu hệ thống không đủ sức phục vụ lưu lượng cao hơn. Trong báo cáo, 429 được tính vào lỗi và là cơ sở để cân nhắc tăng hạn mức hoặc quy mô hệ thống.
	
	\item \textbf{Lỗi 5xx (500, 502, 503...):} Các mã lỗi 5xx ám chỉ lỗi phía server – đây thường là những vấn đề nghiêm trọng được phơi bày khi tải cao. Ví dụ: \textit{500 Internal Server Error} do bug trong code bị lộ ra dưới cạnh tranh đa luồng; \textit{502/503 Bad Gateway/Service Unavailable} do một service con bị sập; \textit{504 Gateway Timeout} khi một thành phần down-line không phản hồi kịp. Khi Locust báo nhiều lỗi 5xx, nhóm ứng dụng cần điều tra nguyên nhân gốc: có thể do quá tải tài nguyên (CPU, RAM, kết nối database) dẫn đến sập dịch vụ, hoặc lỗi logic không xuất hiện ở tải thấp nhưng xảy ra ở tải cao. Những lỗi này thường ưu tiên sửa chữa trước khi tiến hành tải tiếp.
	
	\item \textbf{Rò rỉ session hoặc resource leak:} Test nhiều ngày kéo dài có thể phát hiện các vấn đề rò rỉ tài nguyên. Một ví dụ phổ biến là rò rỉ session: nếu ứng dụng web tạo session cho mỗi người dùng đăng nhập nhưng không giải phóng đúng cách, số session tích tụ dần sẽ chiếm dần dung lượng ngày càng nhiều bộ nhớ hoặc không gian lưu trữ. Tương tự, có thể rò rỉ các thứ khác như kết nối cơ sở dữ liệu (không đóng), handle file, bộ nhớ của ứng dụng dẫn đến treo theo thời gian chạy. Locust giúp phát hiện điều này khi nhận thấy hiệu năng giảm dần hoặc hệ thống chậm lại rõ rệt sau một thời gian chạy liên tục. Quan sát đồ thị có thể thấy, chẳng hạn, ban đầu ứng dụng nhanh nhưng sau đó bị chậm hẳn, có thể nghi ngờ rò rỉ và cần xem log, giám sát memory để xác nhận.
	
	\item \textbf{Nút cổ chai ở cơ sở dữ liệu:} Database thường là thành phần dễ trở thành điểm nghẽn dưới tải cao. Các dấu hiệu gồm: thời gian phản hồi tăng khi số lượng user tăng (trong khi CPU app server chưa chắc đã max, mà CPU hoặc IO của DB server lại đang báo hao), hoặc xuất hiện lỗi liên quan đến DB như \textit{timeout query}, \textit{connection pool exhausted}, thậm chí lỗi \textit{deadlock} trong DB. Locust thường được dùng để xác định ngưỡng mà tại đó DB không xử lý nổi nữa. Khi thấy throughput không tăng dù thêm user, latency tăng cao, nhiều truy vấn chậm, đó là lúc DB trở thành \textit{bottleneck}. Giải pháp có thể là tối ưu câu query, thêm chỉ mục, hoặc tăng tài nguyên DB/phân chia tải.
	
	\item \textbf{Deadlock và các vấn đề đồng thời:} Tải đa người dùng có thể làm lộ ra bug đồng bộ mà bình thường khó xuất hiện. \textit{Deadlock} là ví dụ điển hình – xảy ra khi hai hoặc nhiều tiến trình chờ nhau giữ khóa tài nguyên và không tiến triển. Trong hệ thống web, deadlock có thể xảy ra ở cấp ứng dụng (code) hoặc ở cấp database (các giao dịch khóa bảng/theo thứ tự khác nhau). Locust chạy hàng trăm, hàng ngàn user đồng thời có thể khiến những tình huống race condition hoặc deadlock này xảy ra tương đối thường xuyên (ví dụ gặp lỗi deadlock trên SQL trả về hoặc thread dump của ứng dụng cho thấy nhiều thread chờ lock). Phát hiện sớm deadlock cực kỳ quan trọng vì nó gây treo dịch vụ. Nhờ test, đội ngũ phát triển có thể bổ sung cơ chế timeout, thay đổi thứ tự khóa hoặc sửa logic để loại bỏ tình trạng deadlock.
	
\end{itemize}

